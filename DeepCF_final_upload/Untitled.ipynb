{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from Dataset_ml import Dataset\n",
    "from DMF_conv import DMF\n",
    "from evaluate_deepcf import evaluate_model\n",
    "\n",
    "\n",
    "\n",
    "from utils_deepcf import (AverageMeter, BatchDataset, get_optimizer,\n",
    "                   get_train_instances, get_train_matrix, TestDataset)\n",
    "\n",
    "\n",
    "import math\n",
    "import heapq  # for retrieval topK\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import torch\n",
    "from utils_deepcf import TestDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset('Data\\ml-1m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, testRatings, testNegatives = dataset.trainMatrix, dataset.testRatings, dataset.testNegatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_testRatings = testRatings\n",
    "_testNegatives = testNegatives\n",
    "_K = 10\n",
    "num_thread = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-bd540b0edec8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# Single thread\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_testRatings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[1;33m(\u001b[0m\u001b[0mhr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndcg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval_one_rating\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mhits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mndcgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mndcg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-8926c845ca7a>\u001b[0m in \u001b[0;36meval_one_rating\u001b[1;34m(idx)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mldr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0m_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name '_model' is not defined"
     ]
    }
   ],
   "source": [
    "hits, ndcgs = [], []\n",
    "if num_thread > 1:  # Multi-thread\n",
    "    pool = multiprocessing.Pool(processes = num_thread)\n",
    "    res = pool.map(eval_one_rating, range(len(_testRatings)))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    hits = [r[0] for r in res]\n",
    "    ndcgs = [r[1] for r in res]\n",
    "    \n",
    "# Single thread\n",
    "for idx in range(len(_testRatings)):\n",
    "    (hr, ndcg) = eval_one_rating(idx)\n",
    "    hits.append(hr)\n",
    "    ndcgs.append(ndcg)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_one_rating(idx):\n",
    "    rating = _testRatings[idx]\n",
    "    items = _testNegatives[idx]\n",
    "    u = rating[0]\n",
    "    gtItem = rating[1]\n",
    "    items.append(gtItem)\n",
    "    \n",
    "    # Get prediction scores\n",
    "    map_item_score = {}\n",
    "    users = np.full(len(items), u, dtype='int32')\n",
    "   \n",
    "    # ---\n",
    "    isCuda = torch.cuda.is_available()\n",
    "    dst = TestDataset(users, items)\n",
    "    ldr = torch.utils.data.DataLoader(dst, batch_size=100, shuffle=False)\n",
    "\n",
    "    _model.eval()\n",
    "    predictions = [None] * len(dst)\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for ui, ii in ldr:\n",
    "            if isCuda:\n",
    "                ui, ii = ui.cuda(), ii.cuda()\n",
    "            bsz = ui.size(0)\n",
    "            ri = _model(ui, ii).squeeze().cpu().tolist()\n",
    "            predictions[total:total+bsz] = ri\n",
    "    # predictions = _model.predict([users, np.array(items)], \n",
    "    #                              batch_size=100, verbose=0)\n",
    "    # ---\n",
    "    for i in range(len(items)):\n",
    "        item = items[i]\n",
    "        map_item_score[item] = predictions[i]\n",
    "    items.pop()\n",
    "    \n",
    "    # Evaluate top rank list\n",
    "    ranklist = heapq.nlargest(_K, map_item_score, key=map_item_score.get)\n",
    "    hr = getHitRatio(ranklist, gtItem)\n",
    "    ndcg = getNDCG(ranklist, gtItem)\n",
    "    return (hr, ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_testNegatives[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = _testRatings[idx]\n",
    "items = _testNegatives[idx]\n",
    "n_items = items\n",
    "u = rating[0]\n",
    "gtItem = rating[1]\n",
    "items.append(gtItem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranklist = [1, 2, 3, 4, 5, 6, 7, 2791, 915, 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "없음\n",
      "없음\n",
      "없음\n",
      "없음\n",
      "없음\n",
      "없음\n",
      "없음\n",
      "없음\n",
      "없음\n",
      "없음\n"
     ]
    }
   ],
   "source": [
    "for i in ranklist:\n",
    "    if i in n_items:\n",
    "        print(i)\n",
    "    else:\n",
    "        print('없음')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1064,\n",
       " 174,\n",
       " 2791,\n",
       " 3373,\n",
       " 269,\n",
       " 2678,\n",
       " 1902,\n",
       " 3641,\n",
       " 1216,\n",
       " 915,\n",
       " 3672,\n",
       " 2803,\n",
       " 2344,\n",
       " 986,\n",
       " 3217,\n",
       " 2824,\n",
       " 2598,\n",
       " 464,\n",
       " 2340,\n",
       " 1952,\n",
       " 1855,\n",
       " 1353,\n",
       " 1547,\n",
       " 3487,\n",
       " 3293,\n",
       " 1541,\n",
       " 2414,\n",
       " 2728,\n",
       " 340,\n",
       " 1421,\n",
       " 1963,\n",
       " 2545,\n",
       " 972,\n",
       " 487,\n",
       " 3463,\n",
       " 2727,\n",
       " 1135,\n",
       " 3135,\n",
       " 128,\n",
       " 175,\n",
       " 2423,\n",
       " 1974,\n",
       " 2515,\n",
       " 3278,\n",
       " 3079,\n",
       " 1527,\n",
       " 2182,\n",
       " 1018,\n",
       " 2800,\n",
       " 1830,\n",
       " 1539,\n",
       " 617,\n",
       " 247,\n",
       " 3448,\n",
       " 1699,\n",
       " 1420,\n",
       " 2487,\n",
       " 198,\n",
       " 811,\n",
       " 1010,\n",
       " 1423,\n",
       " 2840,\n",
       " 1770,\n",
       " 881,\n",
       " 1913,\n",
       " 1803,\n",
       " 1734,\n",
       " 3326,\n",
       " 1617,\n",
       " 224,\n",
       " 3352,\n",
       " 1869,\n",
       " 1182,\n",
       " 1331,\n",
       " 336,\n",
       " 2517,\n",
       " 1721,\n",
       " 3512,\n",
       " 3656,\n",
       " 273,\n",
       " 1026,\n",
       " 1991,\n",
       " 2190,\n",
       " 998,\n",
       " 3386,\n",
       " 3369,\n",
       " 185,\n",
       " 2822,\n",
       " 864,\n",
       " 2854,\n",
       " 3067,\n",
       " 58,\n",
       " 2551,\n",
       " 2333,\n",
       " 2688,\n",
       " 3703,\n",
       " 1300,\n",
       " 1924,\n",
       " 3118,\n",
       " 25,\n",
       " 25,\n",
       " 25]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2791 in n_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 25]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = 0\n",
    "fp = 0\n",
    "for item in ranklist:\n",
    "    if item == gtItem:\n",
    "        tp += 1\n",
    "    elif item in n_items:\n",
    "        fp += 1\n",
    "    else:\n",
    "        tp = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "29 in n_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get prediction scores\n",
    "map_item_score = {}\n",
    "users = np.full(len(items), u, dtype='int32')\n",
    "\n",
    "# ---\n",
    "isCuda = torch.cuda.is_available()\n",
    "dst = TestDataset(users, items)\n",
    "ldr = torch.utils.data.DataLoader(dst, batch_size=100, shuffle=False)\n",
    "\n",
    "_model.eval()\n",
    "predictions = [None] * len(dst)\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for ui, ii in ldr:\n",
    "        if isCuda:\n",
    "            ui, ii = ui.cuda(), ii.cuda()\n",
    "        bsz = ui.size(0)\n",
    "        ri = _model(ui, ii).squeeze().cpu().tolist()\n",
    "        predictions[total:total+bsz] = ri\n",
    "# predictions = _model.predict([users, np.array(items)], \n",
    "#                              batch_size=100, verbose=0)\n",
    "# ri는 prediction 값으로 0 , 1값이고 그게 prediction에 담김\n",
    "\n",
    "for i in range(len(items)):\n",
    "    item = items[i]\n",
    "    map_item_score[item] = predictions[i]\n",
    "items.pop()\n",
    "\n",
    "# map item score에는 item에 해당 아이템, value에는 해당 아이템에 대한 예측 값\n",
    "# Evaluate top rank list\n",
    "\n",
    "ranklist = heapq.nlargest(_K, map_item_score, key=map_item_score.get)\n",
    "\n",
    "# gtItem은 실제 아이템\n",
    "# ranklist에 들어가 있는 아이템은 \n",
    "hr = getHitRatio(ranklist, gtItem)\n",
    "ndcg = getNDCG(ranklist, gtItem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'items' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-92fc115b3de9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mitems\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'items' is not defined"
     ]
    }
   ],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHitRatio(ranklist, gtItem):\n",
    "    for item in ranklist:\n",
    "        if item == gtItem:\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNDCG(ranklist, gtItem):\n",
    "    for i in range(len(ranklist)):\n",
    "        item = ranklist[i]\n",
    "        if item == gtItem:\n",
    "            return math.log(2) / math.log(i+2)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = _testRatings[0]\n",
    "items = _testNegatives[0]\n",
    "u = rating[0]\n",
    "gtItem = rating[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(items)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
